{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# multimodal_stimulus_fmri_predict/classifiers/multimodal_classifier.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, Tuple\n",
    "from ..core.base_classifier import BaseClassifier\n",
    "\n",
    "class MultiModalClassifier(BaseClassifier):\n",
    "    \"\"\"Multi-modal classifier combining image and fMRI features.\"\"\"\n",
    "    \n",
    "    def build_model(self) -> nn.Module:\n",
    "        \"\"\"Build multi-modal fusion model.\"\"\"\n",
    "        return MultiModalFusionModel(\n",
    "            image_backbone=self.config.get('image_backbone', 'resnet50'),\n",
    "            fmri_input_dim=self.config.get('fmri_input_dim', 1000),\n",
    "            fusion_dim=self.config.get('fusion_dim', 256),\n",
    "            num_classes=self.config.get('num_classes', 2)\n",
    "        )\n",
    "    \n",
    "    def preprocess_data(self, data: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Preprocess both image and fMRI data.\"\"\"\n",
    "        image_data, fmri_data = data\n",
    "        \n",
    "        # Preprocess images\n",
    "        if image_data.shape[1] == 1:\n",
    "            image_data = image_data.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        # Normalize images\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(image_data.device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(image_data.device)\n",
    "        image_data = (image_data - mean) / std\n",
    "        \n",
    "        # Normalize fMRI data\n",
    "        fmri_data = (fmri_data - fmri_data.mean(dim=1, keepdim=True)) / fmri_data.std(dim=1, keepdim=True)\n",
    "        \n",
    "        return image_data, fmri_data\n",
    "\n",
    "\n",
    "class MultiModalFusionModel(nn.Module):\n",
    "    \"\"\"Multi-modal fusion model architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_backbone: str, fmri_input_dim: int, \n",
    "                 fusion_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Image encoder\n",
    "        if image_backbone == 'resnet50':\n",
    "            self.image_encoder = models.resnet50(pretrained=True)\n",
    "            self.image_encoder.fc = nn.Identity()\n",
    "            image_feat_dim = 2048\n",
    "        elif image_backbone == 'efficientnet_b0':\n",
    "            self.image_encoder = models.efficientnet_b0(pretrained=True)\n",
    "            self.image_encoder.classifier = nn.Identity()\n",
    "            image_feat_dim = 1280\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {image_backbone}\")\n",
    "        \n",
    "        # fMRI encoder  \n",
    "        self.fmri_encoder = nn.Sequential(\n",
    "            nn.Linear(fmri_input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Fusion layer\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(image_feat_dim + 256, fusion_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dim, fusion_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dim//2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        image_data, fmri_data = data\n",
    "        \n",
    "        # Extract features\n",
    "        image_features = self.image_encoder(image_data)\n",
    "        fmri_features = self.fmri_encoder(fmri_data)\n",
    "        \n",
    "        # Fuse features\n",
    "        combined_features = torch.cat([image_features, fmri_features], dim=1)\n",
    "        output = self.fusion(combined_features)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
