{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multimodal_stimulus_fmri_predict/classifiers/vision_transformer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTModel, ViTConfig\n",
    "from ..core.base_classifier import BaseClassifier\n",
    "\n",
    "class VisionTransformerClassifier(BaseClassifier):\n",
    "    \"\"\"Vision Transformer classifier for image-based fMRI prediction.\"\"\"\n",
    "    \n",
    "    def build_model(self) -> nn.Module:\n",
    "        \"\"\"Build ViT model with custom classification head.\"\"\"\n",
    "        config = ViTConfig(\n",
    "            image_size=self.config.get('image_size', 224),\n",
    "            patch_size=self.config.get('patch_size', 16),\n",
    "            num_labels=self.config.get('num_classes', 2),\n",
    "            hidden_size=self.config.get('hidden_size', 768),\n",
    "            num_hidden_layers=self.config.get('num_layers', 12),\n",
    "            num_attention_heads=self.config.get('num_heads', 12)\n",
    "        )\n",
    "        \n",
    "        if self.config.get('pretrained', True):\n",
    "            model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "        else:\n",
    "            model = ViTModel(config)\n",
    "        \n",
    "        # Custom classification head\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Linear(model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, self.config.get('num_classes', 2))\n",
    "        )\n",
    "        \n",
    "        return VisionTransformerWrapper(model, classifier)\n",
    "    \n",
    "    def preprocess_data(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Preprocess images for ViT.\"\"\"\n",
    "        # Ensure correct shape: (batch_size, channels, height, width)\n",
    "        if data.dim() == 3:\n",
    "            data = data.unsqueeze(0)\n",
    "        if data.shape[1] != 3:\n",
    "            data = data.repeat(1, 3, 1, 1) if data.shape[1] == 1 else data\n",
    "        \n",
    "        # Normalize to [0, 1] if needed\n",
    "        if data.max() > 1.0:\n",
    "            data = data / 255.0\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "class VisionTransformerWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for ViT with custom head.\"\"\"\n",
    "    \n",
    "    def __init__(self, vit_model: ViTModel, classifier: nn.Module):\n",
    "        super().__init__()\n",
    "        self.vit = vit_model\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.vit(x)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.classifier(pooled_output)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
