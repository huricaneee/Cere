{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7480f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# multimodal_stimulus_fmri_predict/core/base_classifier.py\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import logging\n",
    "\n",
    "class BaseClassifier(ABC):\n",
    "    \"\"\"Abstract base class for all classifiers.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def build_model(self) -> nn.Module:\n",
    "        \"\"\"Build and return the model architecture.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def preprocess_data(self, data: Any) -> Any:\n",
    "        \"\"\"Preprocess input data for the specific classifier.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_loader: DataLoader, val_loader: DataLoader, \n",
    "              epochs: int = 10) -> Dict[str, List[float]]:\n",
    "        \"\"\"Train the classifier.\"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = self.build_model()\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                   lr=self.config.get('learning_rate', 1e-4))\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                data = self.preprocess_data(data)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self.evaluate(val_loader)\n",
    "            history['train_loss'].append(train_loss / len(train_loader))\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            self.logger.info(f'Epoch {epoch+1}/{epochs}: '\n",
    "                           f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "                           f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, data_loader: DataLoader) -> Tuple[float, float]:\n",
    "        \"\"\"Evaluate the classifier.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in data_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                data = self.preprocess_data(data)\n",
    "                \n",
    "                outputs = self.model(data)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        return total_loss / len(data_loader), accuracy\n",
    "    \n",
    "    def predict(self, data: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"Make predictions on new data.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(self.device)\n",
    "            data = self.preprocess_data(data)\n",
    "            outputs = self.model(data)\n",
    "            return torch.softmax(outputs, dim=1).cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
